
def main():

    # Read the saved file of data into an input tensor and a label tensor. Partition along training and validation

    # Create a dataloader or dataset or whatever tensorflow uses

    # Create a model using the same architecture as the end of conversation detection

    # Use a custom layer that preprocesses the input data the same way we were doing in the browser
        # if needed, compare this output to what the end of conversation detection had
    
    # train the model

    # run a validation check. This is VERY IMPORTANT because our problem in the browser was generalization

    print("Done")


if __name__ == "__main__":
    main()
